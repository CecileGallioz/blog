{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set and get hyperparameters (v2)\n",
    "> The process of learning a predictive model is driven by a set of internal parameters and a set of training data. These internal parameters are called hyperparameters and are specific for each family of models. In addition, a specific set of hyperparameters are optimal for a specific dataset and thus they need to be optimized.\n",
    "- toc: true\n",
    "- badges: false\n",
    "- comments: true\n",
    "- author: CÃ©cile Gallioz\n",
    "- categories: [sklearn, v2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = pd.read_csv(\"../../scikit-learn-mooc/datasets/adult-census.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = myData.drop(columns=\"education-num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset data contains 48842 samples and 13 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"The dataset data contains {myData.shape[0]} samples and {myData.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'class'\n",
    "target = myData[target_column]\n",
    "data = myData.drop(columns=target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "# \n",
    "numerical_columns = selector(dtype_exclude=object)(data)\n",
    "categorical_columns = selector(dtype_include=object)(data)\n",
    "all_columns = numerical_columns + categorical_columns\n",
    "data = data[all_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_numerical = data[numerical_columns]\n",
    "data_categorical = data[categorical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy in TRAIN is 0.864 +/- 0.001\n",
      "The accuracy in TEST  is 0.862 +/- 0.001, for 0.512 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "#\n",
    "\n",
    "categorical_preprocessor = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('categorical', categorical_preprocessor, categorical_columns)],\n",
    "    remainder=\"passthrough\")\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", HistGradientBoostingClassifier(random_state=42, max_leaf_nodes=4))])\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "\n",
    "cv_results = cross_validate(model, data, target, cv=cv, return_train_score=True)\n",
    "\n",
    "scores = cv_results[\"test_score\"]\n",
    "train_scores = cv_results[\"train_score\"]\n",
    "fit_time = cv_results[\"fit_time\"]\n",
    "\n",
    "print(\"The accuracy in TRAIN is \"\n",
    "      f\"{train_scores.mean():.3f} +/- {train_scores.std():.3f}\")\n",
    "print(\"The accuracy in TEST  is \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}, for {fit_time.mean():.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put hyperparameter ourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory\n",
      "steps\n",
      "verbose\n",
      "preprocessor\n",
      "classifier\n",
      "preprocessor__n_jobs\n",
      "preprocessor__remainder\n",
      "preprocessor__sparse_threshold\n",
      "preprocessor__transformer_weights\n",
      "preprocessor__transformers\n",
      "preprocessor__verbose\n",
      "preprocessor__verbose_feature_names_out\n",
      "preprocessor__categorical\n",
      "preprocessor__categorical__categories\n",
      "preprocessor__categorical__dtype\n",
      "preprocessor__categorical__handle_unknown\n",
      "preprocessor__categorical__unknown_value\n",
      "classifier__categorical_features\n",
      "classifier__early_stopping\n",
      "classifier__l2_regularization\n",
      "classifier__learning_rate\n",
      "classifier__loss\n",
      "classifier__max_bins\n",
      "classifier__max_depth\n",
      "classifier__max_iter\n",
      "classifier__max_leaf_nodes\n",
      "classifier__min_samples_leaf\n",
      "classifier__monotonic_cst\n",
      "classifier__n_iter_no_change\n",
      "classifier__random_state\n",
      "classifier__scoring\n",
      "classifier__tol\n",
      "classifier__validation_fraction\n",
      "classifier__verbose\n",
      "classifier__warm_start\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.get_params():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score via cross-validation with mln=2:\n",
      "The accuracy in TRAIN is 0.826 +/- 0.001\n",
      "The accuracy in TEST  is 0.825 +/- 0.002, for 0.461 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.set_params(classifier__max_leaf_nodes=2);\n",
    "\n",
    "cv_results = cross_validate(model, data, target, cv=cv, return_train_score=True)\n",
    "\n",
    "scores = cv_results[\"test_score\"]\n",
    "train_scores = cv_results[\"train_score\"]\n",
    "fit_time = cv_results[\"fit_time\"]\n",
    "\n",
    "print(f\"Accuracy score via cross-validation with mln={model.get_params()['classifier__max_leaf_nodes']}:\")\n",
    "print(\"The accuracy in TRAIN is \"\n",
    "  f\"{train_scores.mean():.3f} +/- {train_scores.std():.3f}\")\n",
    "print(\"The accuracy in TEST  is \"\n",
    "  f\"{scores.mean():.3f} +/- {scores.std():.3f}, for {fit_time.mean():.3f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test an hyperparameter manualy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score via cross-validation with mln=3 and lr=0.01:\n",
      "The accuracy in TRAIN is 0.799 +/- 0.001\n",
      "The accuracy in TEST  is 0.799 +/- 0.001, for 0.534 seconds\n",
      "\n",
      "Accuracy score via cross-validation with mln=3 and lr=0.1:\n",
      "The accuracy in TRAIN is 0.857 +/- 0.001\n",
      "The accuracy in TEST  is 0.856 +/- 0.001, for 0.601 seconds\n",
      "\n",
      "Accuracy score via cross-validation with mln=3 and lr=1:\n",
      "The accuracy in TRAIN is 0.865 +/- 0.004\n",
      "The accuracy in TEST  is 0.862 +/- 0.006, for 0.271 seconds\n",
      "\n",
      "Accuracy score via cross-validation with mln=3 and lr=10:\n",
      "The accuracy in TRAIN is 0.281 +/- 0.001\n",
      "The accuracy in TEST  is 0.279 +/- 0.002, for 0.190 seconds\n",
      "\n",
      "Accuracy score via cross-validation with mln=10 and lr=0.01:\n",
      "The accuracy in TRAIN is 0.820 +/- 0.001\n",
      "The accuracy in TEST  is 0.819 +/- 0.002, for 0.808 seconds\n",
      "\n",
      "Accuracy score via cross-validation with mln=10 and lr=0.1:\n",
      "The accuracy in TRAIN is 0.873 +/- 0.001\n",
      "The accuracy in TEST  is 0.870 +/- 0.001, for 0.836 seconds\n",
      "\n",
      "Accuracy score via cross-validation with mln=10 and lr=1:\n",
      "The accuracy in TRAIN is 0.870 +/- 0.002\n",
      "The accuracy in TEST  is 0.865 +/- 0.002, for 0.276 seconds\n",
      "\n",
      "Accuracy score via cross-validation with mln=10 and lr=10:\n",
      "The accuracy in TRAIN is 0.697 +/- 0.106\n",
      "The accuracy in TEST  is 0.696 +/- 0.104, for 0.190 seconds\n",
      "\n",
      "Accuracy score via cross-validation with mln=30 and lr=0.01:\n",
      "The accuracy in TRAIN is 0.850 +/- 0.001\n",
      "The accuracy in TEST  is 0.848 +/- 0.003, for 1.441 seconds\n",
      "\n",
      "Accuracy score via cross-validation with mln=30 and lr=0.1:\n",
      "The accuracy in TRAIN is 0.882 +/- 0.001\n",
      "The accuracy in TEST  is 0.872 +/- 0.001, for 1.430 seconds\n",
      "\n",
      "Accuracy score via cross-validation with mln=30 and lr=1:\n",
      "The accuracy in TRAIN is 0.874 +/- 0.003\n",
      "The accuracy in TEST  is 0.860 +/- 0.003, for 0.298 seconds\n",
      "\n",
      "Accuracy score via cross-validation with mln=30 and lr=10:\n",
      "The accuracy in TRAIN is 0.419 +/- 0.178\n",
      "The accuracy in TEST  is 0.419 +/- 0.177, for 0.201 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for mln in [3, 10, 30]:\n",
    "    for lr in [0.01, 0.1, 1, 10]:\n",
    "        model.set_params(classifier__max_leaf_nodes=mln)\n",
    "        model.set_params(classifier__learning_rate=lr)\n",
    "\n",
    "        cv_results = cross_validate(model, data, target, cv=cv, return_train_score=True)\n",
    "\n",
    "        scores = cv_results[\"test_score\"]\n",
    "        train_scores = cv_results[\"train_score\"]\n",
    "        fit_time = cv_results[\"fit_time\"]\n",
    "\n",
    "        print(f\"Accuracy score via cross-validation with mln={mln} and lr={lr}:\")\n",
    "        print(\"The accuracy in TRAIN is \"\n",
    "          f\"{train_scores.mean():.3f} +/- {train_scores.std():.3f}\")\n",
    "        print(\"The accuracy in TEST  is \"\n",
    "          f\"{scores.mean():.3f} +/- {scores.std():.3f}, for {fit_time.mean():.3f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test an hyperparameter with param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__learning_rate': (0.01, 0.1, 1, 10),\n",
    "    'classifier__max_leaf_nodes': (3, 10, 30)}\n",
    "\n",
    "model_grid_search = GridSearchCV(model, param_grid=param_grid, n_jobs=2, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(model_grid_search, data, target, \n",
    "                            cv=cv, \n",
    "                            return_train_score=True, \n",
    "                            return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy in TRAIN is 0.882 +/- 0.001\n",
      "The accuracy in TEST  is 0.872 +/- 0.001, for 22.876 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = cv_results[\"test_score\"]\n",
    "train_scores = cv_results[\"train_score\"]\n",
    "fit_time = cv_results[\"fit_time\"]\n",
    "best_estimators = cv_results[\"estimator\"]\n",
    "\n",
    "print(\"The accuracy in TRAIN is \"\n",
    "  f\"{train_scores.mean():.3f} +/- {train_scores.std():.3f}\")\n",
    "print(\"The accuracy in TEST  is \"\n",
    "  f\"{scores.mean():.3f} +/- {scores.std():.3f}, for {fit_time.mean():.3f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for fold #1:\n",
      "{'classifier__learning_rate': 0.1, 'classifier__max_leaf_nodes': 30}\n",
      "The accuracy in TRAIN is 0.881\n",
      "The accuracy in TEST  is 0.874, for 23.114 seconds\n",
      "\n",
      "Best hyperparameters for fold #2:\n",
      "{'classifier__learning_rate': 0.1, 'classifier__max_leaf_nodes': 30}\n",
      "The accuracy in TRAIN is 0.882\n",
      "The accuracy in TEST  is 0.871, for 20.990 seconds\n",
      "\n",
      "Best hyperparameters for fold #3:\n",
      "{'classifier__learning_rate': 0.1, 'classifier__max_leaf_nodes': 30}\n",
      "The accuracy in TRAIN is 0.883\n",
      "The accuracy in TEST  is 0.870, for 21.488 seconds\n",
      "\n",
      "Best hyperparameters for fold #4:\n",
      "{'classifier__learning_rate': 0.1, 'classifier__max_leaf_nodes': 30}\n",
      "The accuracy in TRAIN is 0.881\n",
      "The accuracy in TEST  is 0.873, for 21.706 seconds\n",
      "\n",
      "Best hyperparameters for fold #5:\n",
      "{'classifier__learning_rate': 0.1, 'classifier__max_leaf_nodes': 30}\n",
      "The accuracy in TRAIN is 0.882\n",
      "The accuracy in TEST  is 0.873, for 27.082 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cv_fold, estimator_in_fold in enumerate(best_estimators):\n",
    "    print(f\"Best hyperparameters for fold #{cv_fold + 1}:\\n\"\n",
    "        f\"{estimator_in_fold.best_params_}\")\n",
    "    print(\"The accuracy in TRAIN is \"\n",
    "        f\"{train_scores[cv_fold]:.3f}\")\n",
    "    print(\"The accuracy in TEST  is \"\n",
    "      f\"{scores[cv_fold]:.3f}, for {fit_time[cv_fold]:.3f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform\n",
    "\n",
    "\n",
    "class loguniform_int:\n",
    "    \"\"\"Integer valued version of the log-uniform distribution\"\"\"\n",
    "    def __init__(self, a, b):\n",
    "        self._distribution = loguniform(a, b)\n",
    "\n",
    "    def rvs(self, *args, **kwargs):\n",
    "        \"\"\"Random variable sample\"\"\"\n",
    "        return self._distribution.rvs(*args, **kwargs).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#\n",
    "# param_distributions = {\n",
    "#     'classifier__l2_regularization': loguniform(1e-6, 1e3),\n",
    "#     'classifier__learning_rate': loguniform(0.001, 10),\n",
    "#     'classifier__max_leaf_nodes': loguniform_int(2, 256),\n",
    "#     'classifier__min_samples_leaf': loguniform_int(1, 100),\n",
    "#     'classifier__max_bins': loguniform_int(2, 255),\n",
    "# }\n",
    "\n",
    "param_distributions = {\n",
    "    'classifier__learning_rate': loguniform(0.001, 10),\n",
    "    'classifier__max_leaf_nodes': loguniform_int(2, 256)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_random_search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_distributions, n_iter=10,\n",
    "    cv=cv, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(model_random_search, data, target, \n",
    "                            cv=cv, \n",
    "                            return_train_score=True, \n",
    "                            return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy in TRAIN is 0.879 +/- 0.005\n",
      "The accuracy in TEST  is 0.871 +/- 0.002, for 59.890 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = cv_results[\"test_score\"]\n",
    "train_scores = cv_results[\"train_score\"]\n",
    "fit_time = cv_results[\"fit_time\"]\n",
    "best_estimators = cv_results[\"estimator\"]\n",
    "\n",
    "print(\"The accuracy in TRAIN is \"\n",
    "  f\"{train_scores.mean():.3f} +/- {train_scores.std():.3f}\")\n",
    "print(\"The accuracy in TEST  is \"\n",
    "  f\"{scores.mean():.3f} +/- {scores.std():.3f}, for {fit_time.mean():.3f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for fold #1:\n",
      "{'classifier__learning_rate': 0.5360979653669641, 'classifier__max_leaf_nodes': 4}\n",
      "The accuracy in TRAIN is 0.872\n",
      "The accuracy in TEST  is 0.869, for 52.325 seconds\n",
      "\n",
      "Best hyperparameters for fold #2:\n",
      "{'classifier__learning_rate': 0.10420574471319943, 'classifier__max_leaf_nodes': 23}\n",
      "The accuracy in TRAIN is 0.880\n",
      "The accuracy in TEST  is 0.872, for 40.249 seconds\n",
      "\n",
      "Best hyperparameters for fold #3:\n",
      "{'classifier__learning_rate': 0.03086058204962357, 'classifier__max_leaf_nodes': 44}\n",
      "The accuracy in TRAIN is 0.875\n",
      "The accuracy in TEST  is 0.870, for 52.635 seconds\n",
      "\n",
      "Best hyperparameters for fold #4:\n",
      "{'classifier__learning_rate': 0.2072080935893539, 'classifier__max_leaf_nodes': 28}\n",
      "The accuracy in TRAIN is 0.883\n",
      "The accuracy in TEST  is 0.874, for 114.106 seconds\n",
      "\n",
      "Best hyperparameters for fold #5:\n",
      "{'classifier__learning_rate': 0.31645381205607565, 'classifier__max_leaf_nodes': 33}\n",
      "The accuracy in TRAIN is 0.885\n",
      "The accuracy in TEST  is 0.872, for 40.136 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cv_fold, estimator_in_fold in enumerate(best_estimators):\n",
    "    print(f\"Best hyperparameters for fold #{cv_fold + 1}:\\n\"\n",
    "        f\"{estimator_in_fold.best_params_}\")\n",
    "    print(\"The accuracy in TRAIN is \"\n",
    "        f\"{train_scores[cv_fold]:.3f}\")\n",
    "    print(\"The accuracy in TEST  is \"\n",
    "      f\"{scores[cv_fold]:.3f}, for {fit_time[cv_fold]:.3f} seconds\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
