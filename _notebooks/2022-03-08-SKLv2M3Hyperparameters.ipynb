{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set and get hyperparameters (v2)\n",
    "> The process of learning a predictive model is driven by a set of internal parameters and a set of training data. These internal parameters are called hyperparameters and are specific for each family of models. In addition, a specific set of hyperparameters are optimal for a specific dataset and thus they need to be optimized.\n",
    "- toc: true\n",
    "- badges: false\n",
    "- comments: true\n",
    "- author: CÃ©cile Gallioz\n",
    "- categories: [sklearn, v2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = pd.read_csv(\"../../scikit-learn-mooc/datasets/adult-census.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = myData.drop(columns=\"education-num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset data contains 48842 samples and 13 features\n"
     ]
    }
   ],
   "source": [
    "print(f\"The dataset data contains {myData.shape[0]} samples and {myData.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'class'\n",
    "target = myData[target_column]\n",
    "data = myData.drop(columns=target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "# \n",
    "numerical_columns = selector(dtype_exclude=object)(data)\n",
    "categorical_columns = selector(dtype_include=object)(data)\n",
    "all_columns = numerical_columns + categorical_columns\n",
    "data = data[all_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_numerical = data[numerical_columns]\n",
    "data_categorical = data[categorical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression on default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy in TRAIN is 0.800 +/- 0.001\n",
      "The accuracy in TEST  is 0.800 +/- 0.002, for 0.067 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "# \n",
    "\n",
    "model = Pipeline([\n",
    "    (\"preprocessor\", StandardScaler()), \n",
    "    (\"classifier\", LogisticRegression(max_iter=500))])\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "\n",
    "cv_results = cross_validate(model, data_numerical, target, cv=cv, return_train_score=True)\n",
    "\n",
    "scores = cv_results[\"test_score\"]\n",
    "train_scores = cv_results[\"train_score\"]\n",
    "fit_time = cv_results[\"fit_time\"]\n",
    "\n",
    "print(\"The accuracy in TRAIN is \"\n",
    "      f\"{train_scores.mean():.3f} +/- {train_scores.std():.3f}\")\n",
    "print(\"The accuracy in TEST  is \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}, for {fit_time.mean():.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a model with the default `C` value that is equal to 1. If we\n",
    "wanted to use a different `C` parameter we could have done so when we created\n",
    "the `LogisticRegression` object with something like `LogisticRegression(C=1e-3)`.\n",
    "\n",
    "        `C` : Inverse of regularization strength; must be a positive float. Smaller values specify stronger regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put hyperparameter ourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory\n",
      "steps\n",
      "verbose\n",
      "preprocessor\n",
      "classifier\n",
      "preprocessor__copy\n",
      "preprocessor__with_mean\n",
      "preprocessor__with_std\n",
      "classifier__C\n",
      "classifier__class_weight\n",
      "classifier__dual\n",
      "classifier__fit_intercept\n",
      "classifier__intercept_scaling\n",
      "classifier__l1_ratio\n",
      "classifier__max_iter\n",
      "classifier__multi_class\n",
      "classifier__n_jobs\n",
      "classifier__penalty\n",
      "classifier__random_state\n",
      "classifier__solver\n",
      "classifier__tol\n",
      "classifier__verbose\n",
      "classifier__warm_start\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.get_params():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor', StandardScaler()),\n",
       "                ('classifier', LogisticRegression(C=0.001, max_iter=500))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_params(classifier__C=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy in TRAIN is 0.786 +/- 0.001\n",
      "The accuracy in TEST  is 0.786 +/- 0.003, for 0.058 seconds\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(model, data_numerical, target, cv=cv, return_train_score=True)\n",
    "\n",
    "scores = cv_results[\"test_score\"]\n",
    "train_scores = cv_results[\"train_score\"]\n",
    "fit_time = cv_results[\"fit_time\"]\n",
    "\n",
    "print(\"The accuracy in TRAIN is \"\n",
    "      f\"{train_scores.mean():.3f} +/- {train_scores.std():.3f}\")\n",
    "print(\"The accuracy in TEST  is \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}, for {fit_time.mean():.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()['classifier__C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test an hyperparameter manualy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score via cross-validation with C=0.0001:\n",
      "The accuracy in TRAIN is 0.766 +/- 0.001\n",
      "The accuracy in TEST  is 0.766 +/- 0.003, for 0.057 seconds\n",
      "\n",
      "Accuracy score via cross-validation with C=0.001:\n",
      "The accuracy in TRAIN is 0.786 +/- 0.001\n",
      "The accuracy in TEST  is 0.786 +/- 0.003, for 0.059 seconds\n",
      "\n",
      "Accuracy score via cross-validation with C=0.01:\n",
      "The accuracy in TRAIN is 0.799 +/- 0.001\n",
      "The accuracy in TEST  is 0.799 +/- 0.002, for 0.061 seconds\n",
      "\n",
      "Accuracy score via cross-validation with C=0.1:\n",
      "The accuracy in TRAIN is 0.800 +/- 0.001\n",
      "The accuracy in TEST  is 0.800 +/- 0.002, for 0.063 seconds\n",
      "\n",
      "Accuracy score via cross-validation with C=1:\n",
      "The accuracy in TRAIN is 0.800 +/- 0.001\n",
      "The accuracy in TEST  is 0.800 +/- 0.002, for 0.063 seconds\n",
      "\n",
      "Accuracy score via cross-validation with C=10:\n",
      "The accuracy in TRAIN is 0.800 +/- 0.001\n",
      "The accuracy in TEST  is 0.800 +/- 0.002, for 0.063 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for C in [1e-4, 1e-3, 1e-2, 1e-1, 1, 10]:\n",
    "    model.set_params(classifier__C=C)\n",
    "    \n",
    "    cv_results = cross_validate(model, data_numerical, target, cv=cv, return_train_score=True)\n",
    "    \n",
    "    scores = cv_results[\"test_score\"]\n",
    "    train_scores = cv_results[\"train_score\"]\n",
    "    fit_time = cv_results[\"fit_time\"]\n",
    "    \n",
    "    print(f\"Accuracy score via cross-validation with C={C}:\")\n",
    "    print(\"The accuracy in TRAIN is \"\n",
    "          f\"{train_scores.mean():.3f} +/- {train_scores.std():.3f}\")\n",
    "    print(\"The accuracy in TEST  is \"\n",
    "          f\"{scores.mean():.3f} +/- {scores.std():.3f}, for {fit_time.mean():.3f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that as long as `C` is high enough, the model seems to perform\n",
    "well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
